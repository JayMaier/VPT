
step 0
recon loss: 0.246
discr loss: 1.924
validation recon loss 0.356
validation EMA recon loss 0.356
sample saved to results/sampled.0.gif
step 1
recon loss: 0.563
discr loss: 1.476
step 2
recon loss: 0.272
discr loss: 0.840
step 3
recon loss: 0.272
discr loss: 0.382
step 4
recon loss: 0.507
discr loss: 0.000
step 5
recon loss: 0.077
discr loss: 0.000
step 6
recon loss: 0.189
discr loss: 0.000
step 7
recon loss: 0.237
discr loss: 0.000
step 8
recon loss: 0.246
discr loss: 0.000
step 9
recon loss: 0.563
discr loss: 0.000
step 10
recon loss: 0.563
discr loss: 0.000
step 11
recon loss: 0.507
discr loss: 0.000
step 12
recon loss: 0.189
discr loss: 0.000
step 13
recon loss: 0.077
discr loss: 0.000
step 14
recon loss: 0.077
discr loss: 0.000
step 15
recon loss: 0.108
discr loss: 0.000
step 16
recon loss: 0.272
discr loss: 0.000
step 17
recon loss: 0.507
discr loss: 0.482
step 18
recon loss: 0.507
discr loss: 0.000
step 19
recon loss: 0.077
discr loss: 0.000
step 20
recon loss: 0.077
discr loss: 0.000
step 21
recon loss: 0.246
discr loss: 0.000
step 22
recon loss: 0.104
discr loss: 0.000
step 23
recon loss: 0.563
discr loss: 0.000
step 24
recon loss: 0.507
discr loss: 0.000
step 25
recon loss: 0.507
discr loss: 1.557
step 26
recon loss: 0.563
discr loss: 2.351
step 27
recon loss: 0.246
discr loss: 1.502
step 28
recon loss: 0.189
discr loss: 1.033
step 29
Traceback (most recent call last):
  File "/home/jay/VPT/src/train_magvit.py", line 46, in <module>
    trainer.train()
  File "/home/jay/anaconda3/envs/magvit/lib/python3.12/site-packages/magvit2_pytorch/trainer.py", line 516, in train
    self.train_step(dl_iter)
  File "/home/jay/anaconda3/envs/magvit/lib/python3.12/site-packages/magvit2_pytorch/trainer.py", line 349, in train_step
    loss, loss_breakdown = self.model(
                           ^^^^^^^^^^^
  File "/home/jay/anaconda3/envs/magvit/lib/python3.12/site-packages/pytorch_custom_utils/accelerate_utils.py", line 84, in __call__
    return call_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jay/anaconda3/envs/magvit/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jay/anaconda3/envs/magvit/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<@beartype(magvit2_pytorch.magvit2_pytorch.VideoTokenizer.forward) at 0x7f5411182f20>", line 55, in forward
  File "/home/jay/anaconda3/envs/magvit/lib/python3.12/site-packages/magvit2_pytorch/magvit2_pytorch.py", line 1786, in forward
    input_vgg_input = pick_video_frame(video, frame_indices)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jay/anaconda3/envs/magvit/lib/python3.12/site-packages/magvit2_pytorch/magvit2_pytorch.py", line 94, in pick_video_frame
    images = rearrange(images, 'b 1 c ... -> b c ...')
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jay/anaconda3/envs/magvit/lib/python3.12/site-packages/einops/einops.py", line 536, in rearrange
    def rearrange(tensor: Union[Tensor, List[Tensor]], pattern: str, **axes_lengths) -> Tensor:
KeyboardInterrupt